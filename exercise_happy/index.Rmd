---
title: "World Happiness Report"
output: 
  learnr::tutorial:
    progressive: true
    allow_skip: true
runtime: shiny_prerendered
description: >
  Learn how to explore the World Happiness Report dataset and make some pretty plots!
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(learnr)
gradethis::gradethis_setup()

library(tidyverse)
library(janitor)
library(fontawesome)

happy_full <- read_csv("https://raw.githubusercontent.com/BAREJAA/website_for_john/master/datasets/world-happiness-report-2021.csv") %>% clean_names() %>% rename(region = regional_indicator)

happy_full %>% select(country_name:ladder_score, logged_gdp_per_capita:ladder_score_in_dystopia) %>% relocate(ladder_score_in_dystopia, .after = region) -> happy_select

happy <- read_csv("https://raw.githubusercontent.com/BAREJAA/website_for_john/master/datasets/happy_small.csv")

happy %>% 
  inner_join(happy_full, by = "country_name") %>% 
  select(country_name, healthy_life_expectancy) -> happy_join_one

happy_full %>% 
  filter(!(country_name %in% happy$country_name)) %>% 
  slice_sample(n = 5) %>% 
  select(country_name, healthy_life_expectancy) %>%
  bind_rows(happy_join_one) %>% 
  .[-10 ,] -> happy_join
```

## Analysing the World Happiness Report `r fa("globe-europe")`

In this exercise, you will apply what you've learned in class to perform exploratory data analysis (EDA) on the **World Happiness Report** and make some pretty plots.  

This dataset was downloaded from the website [Kaggle](https://www.kaggle.com/ajaypalsinghlo/world-happiness-report-2021?select=world-happiness-report.csv). We will use the **2021** data in this exercise. This dataset is stored in an object called `happy_full` 

###  

In this exercise, you will practice:

* gaining quick insight into the type of data this dataset contains
* using functions from the Dplyr package to wrangle your data and obtain useful summaries
* making pretty plots!

### Prerequisites

Please watch the recordings on Dplyr and Ggplot2  

## Take a look at your data

### What does the dataset look like?

A couple useful things to know about your dataset are -  
- The number of rows and columns
- The types of variables the dataset contains  

What function can you use to get this information?

```{r glimpse, exercise = TRUE, exercise.eval = FALSE, exercise.cap = "Take a glimpse at your data"}

```

<div id="glimpse-hint">
**Hint:** Try the dplyr `glimpse()` function.
</div>

```{r glimpse-solution}
glimpse(happy_full)
```

```{r glimpse-code-check}
grade_code()
```

### Double data type

We can see that `happy_full` contains many variables that are of type double. 

```{r quiz-double, echo = FALSE}
quiz(
  question("The `double` data type refers to which of the following?",
    answer("A string"),
    answer("An integer"),
    answer("A number with a decimal point", correct = TRUE),
    answer("A factor"))
)
```

## Selecting Variables 

The `happy_full` dataset contains many variables. This gives us the chance to practice our `select()`-ing skills!

### Simple selects

Let's warm up by performing some basic select operations  

How would you select just the columns `region` and `ladder_score`?  

```{r simple-select, exercise = TRUE, exercise.eval = FALSE, exercise.cap = "A simple selection"}

```

```{r simple-select-solution}
happy_full %>% 
  select(region, ladder_score)
```

```{r simple-select-code-check}
grade_code()
```

Now select everything between (and including) `social_support` and `generosity`

```{r select-between, exercise = TRUE, exercise.eval = FALSE, exercise.cap = "Selecting multiple columns"}

```

```{r select-between-solution}
happy_full %>% 
  select(social_support:generosity)
```

```{r select-between-code-check}
grade_code()
```

### Slightly-more-difficult selects  

Let's try something more challenging now. Select all variables that **do not** have underscores in their names

```{r no-underscore, exercise = TRUE, exercise.eval = FALSE, exercise.cap = "No underscores"}

```

<div id="no-underscore-hint">
**Hint:** You'll need a helper function. Also, don't forget `!`
</div>

```{r no-underscore-solution}
happy_full %>% 
  select(!contains("_"))
```

```{r no-underscore-code-check}
grade_code()
```

Helper functions can be really...helpful! Ok, no we're ready to select the variables we will need for the rest of this exercise. Create a new dataframe called `happy_df` that contains the following variables (in the specified order!) - `country_name`, `region`, `ladder_score_in_dystopia`, `logged_gdp_per_capita`, `social_support`, `healthy_life_expectancy`, `freedom_to_make_life_choices`, `generosity`, `perceptions_of_corruption`  

Avoid simply typing out the names of all these variables. Add `glimpse(happy_df)` as the last line to see if you got the right answer.

```{r happy-select, exercise = TRUE, exercise.eval = FALSE, exercise.cap = "Not-so-simple select"}

```

<div id="happy-select-hint">
**Hint:** You'll need a helper function. Also, don't forget `!`
</div>

```{r happy-select-solution}
happy_df <- happy_full %>% 
                select(country_name:ladder_score, logged_gdp_per_capita:ladder_score_in_dystopia) %>%   
                relocate(ladder_score_in_dystopia, .after = region)

glimpse(happy_df)
```

```{r happy-select-code-check}
grade_code()
```

**Note:** `happy_df` hasn't actually been saved anywhere. So we will be using an identical dataset called `happy_select` for the rest of this exercise. 

## Filtering

`happy_select` contains both numeric and character variables, with lots and lots of observations (rows). This gives us a great opportunity to practice our filtering skills!

### Simple filters

Say we're only interested in looking at data for countries in East Asia. How would we do this?

```{r simple-filter, exercise = TRUE, exercise.eval = FALSE, exercise.cap = "Simple filter"}

```

<div id="simple-filter-hint">
**Hint:** To see which major regions are in this dataset, run `unique(happy_select$region)`
</div>

```{r simple-filter-solution}
happy_select %>% 
  filter(region == "East Asia")
```

```{r simple-filter-code-check}
grade_code()
```

### Filter%in%g

Now use `filter()` to only keep data for the following countries - Algeria, Belgium, India, Tunisia, and Uganda. Try to do this without writing multiple filter statements  

```{r multiple-filter, exercise = TRUE, exercise.eval = FALSE, exercise.cap = ""}

```

<div id="multiple-filter-hint">
**Hint:** Try the `%in%` operator
</div>

```{r multiple-filter-solution}
happy_select %>% 
  filter(country_name %in% c("Algeria", "Belgium", "India", "Tunisia", "Uganda"))
```

```{r multiple-filter-code-check}
grade_code()
```

### Numeric filtering

Finally, let's filter out information for countries that have a **below average** ladder score

```{r num-filter, exercise = TRUE, exercise.eval = FALSE, exercise.cap = ""}

```

<div id="num-filter-hint">
**Hint:** Use the base R `mean()` function
</div>

```{r num-filter-solution}
happy_select %>% 
  filter(ladder_score > mean(ladder_score))
```

```{r num-filter-code-check}
grade_code()
```

## Summary statistics

### Which regions are the happiest? 

Let's now find out which are the happiest regions in the world. We'll do this by working out the average `ladder_score` of all the countries in each region  

```{r group-sum, exercise = TRUE, exercise.eval = FALSE, exercise.cap = "The Happiest Regions"}

```

<div id="group-sum-hint">
**Hint:** Remember the best friends, `group_by()` and `summarise()`
</div>

```{r group-sum-solution}
happy_select %>% 
  group_by(region) %>% 
  summarise(mean(ladder_score)) 
```

```{r group-sum-code-check}
grade_code()
```

### Maxed out

Now let's work out the maximum value for each numeric variable, for each region  

```{r max-val, exercise = TRUE, exercise.eval = FALSE, exercise.cap = "Max"}

```

<div id="max-val-hint">
**Hint:** `across()` is helpful here
</div>

```{r max-val-solution}
happy_select %>% 
  group_by(region) %>% 
  summarise(across(where(is.numeric), max))
```

```{r max-val-check}
grade_code()
```

## Plotting distributions

Now we move to the fun part - making pretty plots! Let's begin by getting a sense of the overall distribution of `ladder_score` in `happy_select`

###

```{r dist, exercise = TRUE, exercise.eval = FALSE, exercise.cap = "Plotting a Histogram"}

```


```{r dist-solution}
happy_select %>% 
  ggplot(aes(ladder_score)) +
  geom_histogram()
```

```{r dist-check}
grade_code()
```

### Making improvements

This plot is fine, but it's a little chunky. Let's try a different geom - `geom_density()` - to see what we get

```{r smooth-dist, exercise = TRUE, exercise.eval = FALSE, exercise.cap = "Smooth Histogram"}

```

```{r smooth-dist-solution}
happy_select %>% 
  ggplot(aes(ladder_score)) +
  geom_density()
```

```{r smooth-dist-check}
grade_code()
```

### Density by region

What does the `ladder_score` distribution look like for each region? There are many ways to visualize this. Let's first plot all the distributions on one plot


```{r multi-dist, exercise = TRUE, exercise.eval = FALSE, exercise.cap = "Multiple Histograms"}

```

```{r multi-dist-solution}
happy_select %>% 
  ggplot(aes(ladder_score, fill = region)) +
  geom_density()
```

```{r multi-dist-check}
grade_code()
```

###

Nice! One small problem with this plot is that distributions are overlapping, making it difficult to visualize everything. Which argument can you adjust to improve this plot? Does it go within `aes()` or outside? Why?

### Faceting

Let's consider an alternative way to plot the distributions. Go ahead and use the `facet_wrap()` function to do this

```{r facet, exercise = TRUE, exercise.eval = FALSE, exercise.cap = "Facet"}

```

```{r facet-solution}
happy_select %>% 
  ggplot(aes(ladder_score)) +
  geom_density() +
  facet_wrap(~region)
```

```{r facet-check}
grade_code()
```

## Scatterplots

### Are rich countries "happier"?

We can use scatterplots to visualize the relationship between two variables. For example, let's take a look at the relationship between `ladder_score` and `logged_gdp_per_capita` (this relationship might be obvious, but maybe we'll be surprised!)

```{r scatter, exercise = TRUE, exercise.eval = FALSE, exercise.cap = "Scatter"}

```

```{r scatter-solution}
happy_select %>% 
  ggplot(aes(logged_gdp_per_capita, ladder_score)) +
  geom_point()
```

```{r scatter-check}
grade_code()
```

### Emphasizing relationships

It's clear from the previous scatterplot that relationship between `ladder_score` and `logged_gdp_per_capita` is positive, and it looks pretty linear. To highlight this, we can use the `geom_smooth()` geom (remember to set the `se` argument to equal `FALSE` to just get a straight line)

```{r smooth, exercise = TRUE, exercise.eval = FALSE, exercise.cap = "Smooth"}

```

```{r smooth-solution}
happy_select %>% 
  ggplot(aes(ladder_score, logged_gdp_per_capita)) +
  geom_point() +
  geom_smooth(se = FALSE)
```

```{r smooth-check}
grade_code()
```

## Making things prettier

The plots we've made, while nice, look a little...basic. Let's try to make some improvements. We'll use the last plot

```{r final-plot, warning = FALSE, message = FALSE}
happy_select %>% 
  ggplot(aes(ladder_score, logged_gdp_per_capita)) +
  geom_point() +
  geom_smooth(se = FALSE) +
  labs(title = "Does Money == Happiness?",
       subtitle = "Plotting Ladder Score against Log GDP Per Capita",
       x = "Log GDP Per Capita",
       y = "Ladder Score") +
  theme_minimal()
```

## Joins

Let's now practice combining datasets by using the Join family of functions from the Dplyr package

The two datasets we will be combining are called `happy` and `happy_join`. These are both tiny datasets that will make it easier to understand what the `*_join()` functions are doing  

Let's first familiarize ourselves with these two datasets -

###
`happy`
```{r happy, echo = FALSE}
happy %>% 
  knitr::kable()
```

###
`happy_join`  
```{r happy_join, echo = FALSE}
happy_join %>% 
  knitr::kable()
```

### `left_join()`

A requirement for all joins is the presence of a variable that is **common** to both datasets being joined. In the case of `happy` and `happy_join` this variable is `country_name` 

Let's perform a `left_join()` on this variable and then examine the output

```{r left-join, exercise = TRUE, exercise.eval = FALSE, exercise.cap = "Scatter"}

```

```{r left-join-solution}
happy %>% 
  left_join(happy_join, by = "country_name")
```

```{r left-join-check}
grade_code()
```

###
Compare this output to `happy`. Notice that we now have additional information on healthy life expectancy for all the countries in `happy` *except* for Spain. The reason for the `NA` for Spain in this category is because this information is missing from `happy_join`  

So you can see how we can use `left_join()` to add new variable(s) to our dataset

### `right_join()`

Now do a right join, recalling that this is syntactically identical to a left join except you replace "left" with "right"

```{r right-join, exercise = TRUE, exercise.eval = FALSE, exercise.cap = "Scatter"}

```

```{r right-join-solution}
happy %>% 
  right_join(happy_join, by = "country_name")
```

```{r right-join-check}
grade_code()
```

###
Carefully look at the output. How is this different from a left join? In this output we only retain countries found in `happy_join`. Along with the `healthy_life_expectancy` variable, we also have three additional variables - `ladder_score`, `gdp`, and `social_support` - obtained from the `happy` dataset. Again, countries that are non-overlapping between these two datasets have NAs for these additional variables   

So you can think of a right join as being the inverse of a left join

### `inner_join()`

Again, run the code for an inner join and we'll then take a look at the output

```{r inner-join, exercise = TRUE, exercise.eval = FALSE, exercise.cap = "Scatter"}

```

```{r inner-join-solution}
happy %>% 
  inner_join(happy_join, by = "country_name")
```

```{r inner-join-check}
grade_code()
```

###
Here we see that we produce a dataset that only contains countries that are common to both `happy` and `happy_join`. This dataset also contains all the variables from both original datasets, and has the nice feature of not containing any missing values (i.e. NAs)

This is a useful join to use if you want your output to be complete and not contain any missing data

### `full_join()`

Let's complete this section with the most complete join - the full join

```{r full-join, exercise = TRUE, exercise.eval = FALSE, exercise.cap = "Scatter"}

```

```{r full-join-solution}
happy %>% 
  full_join(happy_join, by = "country_name")
```

```{r full-join-check}
grade_code()
```

###
As the name indicates, this is the most complete join that produces a dataset that contains all the information from both `happy` and `happy_join`. Use this if you don't want to discard any data during your data wrangling